
## Introduction
While working as an AI trainer and data annotator, I observed firsthand how subtle biases embedded within training datasets disproportionately misclassified several vulnerable groups especially marginalized groups, including those from lower socioeconomic backgrounds. Furthermore, the increasing democratization of AI development and deployment has introduced a new layer of ethical complexities. This experience illuminated how technologies designed with universal aspirations can replicate and amplify existing social issues including inequalities. My combined experience working directly with vulnerable communities through field research, volunteer work and participating in AI development affords me a unique perspective bridging technical understanding and social empathy, a perspective critically needed in contemporary AI governance.

## Academic and Professional Journey
My academic foundation in Sociology, specializing in big data applications in social science (GPA: 3.79/4.0), provided me with the theoretical frameworks and methodological tools necessary to examine technology's social impacts. My undergraduate thesis, which analyzed cultural intermediary practices in social media trends, demonstrated how digital platforms shape cultural narratives, particularly during periods of social isolation. This research honed my abilities in multimodal critical discourse analysis and social network analysis, enabling me to uncover hidden patterns of influence and exclusion within digital spaces.
My professional trajectory has intentionally spanned both technical and social domains. Working as an AI trainer and data annotator for technology companies provided direct insight into the construction of algorithmic systems, including their inherent limitations and biases. Concurrently, my past internships at the Center for Southeast Asian Social Studies and the Centre for Strategic and International Studies Indonesia provided opportunities to examine the impact of these technologies on regional social structures and policy development. This dual perspective has been instrumental in developing my nuanced understanding of AI's societal implications.

## Specific Interest in AI and Vulnerable Communities
My commitment to examining AI's impact on women and children in impoverished urban communities stems from both professional observations and personal engagement. Through field research, volunteer work with feminist communities and educational programs for underprivileged children, I have observed the digital divide not merely as a matter of access but also as a matter of representation within technological systems. My published articles on digital activism and gender bias have explored how technology can both empower and marginalize vulnerable groups.
During my procurement role, where I improved budget efficiency through data monitoring by 15-40%, I observed how automated decision-making systems often failed to account for informal economic activities, predominantly performed by women in impoverished urban communities. This systematic invisibility within data systems directly impacts resource allocation and policy interventions. My combined experience in data analysis, community engagement, and critical theory provides me with the interdisciplinary lens necessary to address these complex challenges.

##Conclusion
As AI systems increasingly mediate access to essential services and opportunities, ensuring these technologies serve, rather than harm, vulnerable populations is not merely a technical challenge but a matter of social justice. My diverse background, encompassing technical AI training, sociological research, community engagement, and creative practice, allows me to approach this challenge with both analytical rigor and human empathy. Through the IAPS fellowship, I hope to contribute to building technological systems that recognize and respect the full humanity of those most vulnerable to technological harm.
